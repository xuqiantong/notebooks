{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "# import scripts.lib as lib\n",
    "\n",
    "# Speech\n",
    "import soundfile as sf # pip install pysoundfile\n",
    "import python_speech_features as speech_lib # pip install python_speech_features\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speakers_file = '/datasets01/librispeech/062419/SPEAKERS.TXT'\n",
    "\n",
    "with open(speakers_file) as f:\n",
    "    content = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172, 2)\n",
      "Speaker id :    14, gender class : 0\n",
      "Speaker id :    16, gender class : 0\n",
      "Speaker id :    17, gender class : 1\n",
      "Speaker id :    19, gender class : 0\n",
      "Speaker id :    22, gender class : 0\n",
      "Speaker id :    23, gender class : 0\n",
      "Speaker id :    26, gender class : 1\n",
      "Speaker id :    27, gender class : 1\n",
      "Speaker id :    28, gender class : 0\n",
      "Speaker id :    30, gender class : 0\n"
     ]
    }
   ],
   "source": [
    "id_speaker = np.array([], dtype=int)\n",
    "gender_speaker = np.array([], dtype=int)\n",
    "for line in content:\n",
    "    if 'train-clean-' in line:\n",
    "        id_speaker = np.append(id_speaker, int(line.split('|')[0]))\n",
    "        if 'F' in line.split('|')[1]:\n",
    "            gender_speaker = np.append(gender_speaker,0)\n",
    "        elif 'M' in line.split('|')[1]:\n",
    "            gender_speaker = np.append(gender_speaker,1)\n",
    "\n",
    "gender_speaker = np.asarray(gender_speaker)\n",
    "id_speaker = np.asarray(id_speaker)\n",
    "train_metadata = np.concatenate([np.expand_dims(id_speaker, axis=1).T, np.expand_dims(gender_speaker,axis=1).T]).T\n",
    "\n",
    "print(train_metadata.shape)\n",
    "for row  in train_metadata[:10]:\n",
    "    print(\"Speaker id : {:5d}, gender class : {:d}\".format(row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146, 2)\n",
      "Speaker id :    61, gender class : 1\n",
      "Speaker id :    84, gender class : 0\n",
      "Speaker id :   116, gender class : 1\n",
      "Speaker id :   121, gender class : 0\n",
      "Speaker id :   174, gender class : 1\n",
      "Speaker id :   237, gender class : 0\n",
      "Speaker id :   251, gender class : 1\n",
      "Speaker id :   260, gender class : 1\n",
      "Speaker id :   367, gender class : 0\n",
      "Speaker id :   422, gender class : 1\n"
     ]
    }
   ],
   "source": [
    "id_speaker = np.array([], dtype=int)\n",
    "gender_speaker = np.array([], dtype=int)\n",
    "for line in content:\n",
    "    if 'dev-' in line or 'test-' in line:\n",
    "        id_speaker = np.append(id_speaker, int(line.split('|')[0]))\n",
    "        if 'F' in line.split('|')[1]:\n",
    "            gender_speaker = np.append(gender_speaker,0)\n",
    "        elif 'M' in line.split('|')[1]:\n",
    "            gender_speaker = np.append(gender_speaker,1)\n",
    "\n",
    "gender_speaker = np.asarray(gender_speaker)\n",
    "id_speaker = np.asarray(id_speaker)\n",
    "test_metadata = np.concatenate([np.expand_dims(id_speaker, axis=1).T, np.expand_dims(gender_speaker,axis=1).T]).T\n",
    "\n",
    "print(test_metadata.shape)\n",
    "for row  in test_metadata[:10]:\n",
    "    print(\"Speaker id : {:5d}, gender class : {:d}\".format(row[0],row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([614269,     73])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/datasets01/librispeech/062419/'\n",
    "\n",
    "N_FEAT = 40\n",
    "TYPE_FEAT = 'mfsc'\n",
    "\n",
    "def get_folder(speaker_id):\n",
    "    folders = ['train-other-500', 'train-clean-360', 'train-clean-100', 'dev-clean', 'dev-other', 'test-clean', 'test-other']\n",
    "    for f in folders:\n",
    "        speaker_folder = os.path.join(data_root, f, speaker_id)\n",
    "        if os.path.exists(speaker_folder):\n",
    "            return speaker_folder\n",
    "\n",
    "def create_dataset(metadata, feat_type='mfsc', nfeat=13):\n",
    "    \"\"\"Creates dataset from metadata with format [speaker_id, speaker_gendeer]\"\"\"\n",
    "    \n",
    "    dataset = np.ndarray(shape=(0,nfeat))\n",
    "    gender_vector = np.ndarray(shape=(0,1))\n",
    "    for speaker_id, gender in metadata:\n",
    "        speaker_folder = get_folder(str(int(speaker_id)))\n",
    "        for root, dirs, files in os.walk(speaker_folder):\n",
    "            for name in files:\n",
    "                if name.endswith(\".flac\"):\n",
    "                    filepath = os.path.join(root,name)\n",
    "                    with open(filepath, 'rb') as f:\n",
    "                    \n",
    "                        signal, samplerate = sf.read(f)\n",
    "\n",
    "                        if feat_type == 'mfcc':\n",
    "                            feat = speech_lib.mfcc(signal,samplerate,winlen=0.060,winstep=0.03,numcep=nfeat,nfilt=nfeat,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,ceplifter=22,appendEnergy=False)\n",
    "                        elif feat_type == 'mfsc':\n",
    "                            feat = speech_lib.logfbank(signal, samplerate, nfilt=nfeat)\n",
    "                        else:\n",
    "                            print(\"Unknow feature type\", feat_type)\n",
    "                            exit(0)\n",
    "                            \n",
    "                        mean_feat = np.expand_dims(np.mean(feat,axis=0),axis=1).T\n",
    "                        dataset = np.append(dataset,mean_feat,axis=0)\n",
    "                        gender_vector = np.append(gender_vector,np.expand_dims(gender*np.ones(mean_feat.shape[0]),axis=1),axis=0)\n",
    "                        \n",
    "    return dataset, gender_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mfsc, y_mfsc = create_dataset(train_metadata, TYPE_FEAT, N_FEAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132553, 40)\n",
      "(132553, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_mfsc.shape)\n",
    "print(y_mfsc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(train_data):\n",
    "    \"\"\"Normalize training data to have mean 0 and variance 1, then apply the same treatment to test data\"\"\"\n",
    "\n",
    "    means = np.mean(train_data,axis=0)\n",
    "    stds = np.std(train_data,axis=0)\n",
    "    \n",
    "    normalized_train_data = (train_data-means)/stds    \n",
    "    return normalized_train_data, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(filepath):\n",
    "    if filepath in feat_dic[TYPE_FEAT]:\n",
    "        print('using feat')\n",
    "        x = feat_dic[TYPE_FEAT][filepath]\n",
    "    else:\n",
    "        with open(filepath, 'rb') as f:                    \n",
    "            signal, samplerate = sf.read(f)\n",
    "            # feat = speech_lib.mfcc(signal,samplerate,winlen=0.060,winstep=0.03,numcep=nfeat,nfilt=nfeat,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,ceplifter=22,appendEnergy=False)\n",
    "            feat = speech_lib.logfbank(signal, samplerate, nfilt=N_FEAT)\n",
    "            x = np.expand_dims(np.mean(feat,axis=0),axis=1).T\n",
    "            x = (x - means) / stds\n",
    "            feat_dic[TYPE_FEAT][filepath] = x\n",
    "            # print(feat_dic)\n",
    "    return clf.predict(x)\n",
    "\n",
    "def test_classifier(metadata):\n",
    "    results = []\n",
    "    for speaker_id, gender in metadata:\n",
    "        speaker_folder = get_folder(str(int(speaker_id)))\n",
    "        filepaths = []\n",
    "        for root, dirs, files in os.walk(speaker_folder):\n",
    "            for name in files:\n",
    "                if name.endswith(\".flac\"):\n",
    "                    filepaths.append(os.path.join(root,name))\n",
    "        \n",
    "        pool = Pool(20)\n",
    "        preds = pool.map(get_pred, filepaths)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "        # print(preds)\n",
    "        pred = round(np.mean(preds))\n",
    "        print(speaker_id, pred, gender)\n",
    "        results.append(pred == gender)\n",
    "    print(sum(results) / len(results))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-acc019c355c8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-acc019c355c8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    feat_dic = {'mfsc' : {}, 'mfcc' : {}}x, means, stds = normalize_data(x_mfsc)\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "feat_dic = {'mfsc' : {}, 'mfcc' : {}}\n",
    "x, means, stds = normalize_data(x_mfsc)\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(x, np.squeeze(y_mfsc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 1.0 1\n",
      "84 0.0 0\n",
      "116 1.0 1\n",
      "121 0.0 0\n",
      "174 0.0 1\n",
      "237 0.0 0\n",
      "251 1.0 1\n",
      "260 1.0 1\n",
      "367 0.0 0\n",
      "422 1.0 1\n",
      "533 0.0 0\n",
      "652 1.0 1\n",
      "672 1.0 1\n",
      "700 0.0 0\n",
      "777 1.0 1\n",
      "908 1.0 1\n",
      "1089 1.0 1\n",
      "1188 1.0 1\n",
      "1221 0.0 0\n",
      "1255 1.0 1\n",
      "1272 1.0 1\n",
      "1284 0.0 0\n",
      "1320 1.0 1\n",
      "1462 0.0 0\n",
      "1580 0.0 0\n",
      "1585 0.0 0\n",
      "1630 0.0 0\n",
      "1650 1.0 1\n",
      "1651 1.0 1\n",
      "1673 0.0 0\n",
      "1686 0.0 0\n",
      "1688 0.0 1\n",
      "1701 1.0 1\n",
      "1919 0.0 0\n",
      "1988 0.0 0\n",
      "1993 0.0 0\n",
      "1995 0.0 0\n",
      "1998 0.0 0\n",
      "2033 1.0 1\n",
      "2035 0.0 0\n",
      "2078 1.0 1\n",
      "2086 1.0 1\n",
      "2094 0.0 0\n",
      "2277 0.0 0\n",
      "2300 1.0 1\n",
      "2412 0.0 0\n",
      "2414 1.0 1\n",
      "2428 1.0 1\n",
      "2506 0.0 0\n",
      "2609 1.0 1\n",
      "2803 1.0 1\n",
      "2830 1.0 1\n",
      "2902 1.0 1\n",
      "2961 0.0 0\n",
      "3000 1.0 1\n",
      "3005 1.0 1\n",
      "3080 0.0 0\n",
      "3081 0.0 0\n",
      "3170 1.0 1\n",
      "3331 1.0 0\n",
      "3528 1.0 0\n",
      "3536 0.0 0\n",
      "3538 0.0 0\n",
      "3570 0.0 0\n",
      "3575 0.0 0\n",
      "3576 0.0 0\n",
      "3660 1.0 1\n",
      "3663 0.0 0\n",
      "3729 0.0 0\n",
      "3752 1.0 1\n",
      "3764 0.0 0\n",
      "3853 0.0 0\n",
      "3915 0.0 0\n",
      "3997 1.0 0\n",
      "4077 1.0 1\n",
      "4153 0.0 0\n",
      "4198 1.0 1\n",
      "4294 0.0 0\n",
      "4323 0.0 0\n",
      "4350 1.0 1\n",
      "4446 0.0 0\n",
      "4507 0.0 0\n",
      "4515 1.0 1\n",
      "4570 1.0 1\n",
      "4572 1.0 1\n",
      "4831 0.0 0\n",
      "4852 1.0 1\n",
      "4970 0.0 0\n",
      "4992 0.0 0\n",
      "5105 1.0 1\n",
      "5142 0.0 0\n",
      "5338 0.0 0\n",
      "5442 0.0 0\n",
      "5484 0.0 0\n",
      "5536 1.0 1\n",
      "5543 0.0 0\n",
      "5639 1.0 1\n",
      "5683 0.0 0\n",
      "5694 1.0 1\n",
      "5764 1.0 1\n",
      "5849 0.0 0\n",
      "5895 0.0 0\n",
      "6070 0.0 0\n",
      "6123 0.0 0\n",
      "6128 0.0 0\n",
      "6241 1.0 1\n",
      "6267 1.0 1\n",
      "6295 1.0 1\n",
      "6313 0.0 0\n",
      "6319 0.0 0\n",
      "6345 0.0 0\n",
      "6432 1.0 1\n",
      "6455 0.0 0\n",
      "6467 1.0 1\n",
      "6599 1.0 1\n",
      "6829 0.0 0\n",
      "6841 1.0 1\n",
      "6930 1.0 1\n",
      "6938 0.0 0\n",
      "7018 1.0 1\n",
      "7021 1.0 1\n",
      "7105 0.0 1\n",
      "7127 1.0 1\n",
      "7176 1.0 1\n",
      "7601 1.0 1\n",
      "7641 0.0 1\n",
      "7697 1.0 1\n",
      "7729 1.0 1\n",
      "7850 0.0 0\n",
      "7902 1.0 1\n",
      "7975 1.0 1\n",
      "7976 0.0 1\n",
      "8131 1.0 1\n",
      "8173 0.0 0\n",
      "8188 1.0 1\n",
      "8224 1.0 1\n",
      "8230 1.0 1\n",
      "8254 0.0 0\n",
      "8280 0.0 0\n",
      "8288 1.0 1\n",
      "8297 1.0 1\n",
      "8455 1.0 1\n",
      "8461 0.0 0\n",
      "8463 0.0 0\n",
      "8555 0.0 0\n",
      "8842 0.0 0\n",
      "0.9452054794520548\n"
     ]
    }
   ],
   "source": [
    "test_classifier(test_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('/private/home/qiantong/gender_classifier/svm_mfsc40_acc95.bin', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 4}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = set([1,2,3,4])\n",
    "b = a.pop()\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sklearn.svm' from '/private/home/qiantong/.local/lib/python3.6/site-packages/sklearn/svm/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
